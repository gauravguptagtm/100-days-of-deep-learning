{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8kcl1ulbjMgo5K4T5SCKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravguptagtm/100-days-of-deep-learning/blob/main/DL_19_Batch_Normalizarion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Batch Norm?\n",
        "\n",
        "Batch Normalization is an algo method which makes the training of DNN faster and more stable.\n",
        "\n",
        "It consist of normalizing activation vectors from hidden layers using te mean and variance of the current batch. This normalization step is applied right before or after the non linear function.\n",
        "\n",
        "# Why use it?\n",
        "if we have unnormalized data, contour of cost function stretched at one side. Because of it, we take small lr and training get slow.\n",
        "After normalizing the data, contour of cost function unifrom in both side. This help in acheive minima faster and stable.\n",
        "\n",
        "So we normalize at each layer which is batch norm.\n",
        "\n",
        "# Covariate shift\n",
        "\n",
        " It is when the distribution of input data shifts between the training environment and live environment. Although the input distribution may change, the output distribution or labels remain the same.\n",
        "\n",
        " Also help in remove covariate shift.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "PGuHP3gqpOlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages**\n",
        "\n",
        "- Stable -> hyperparameter -> wider range of values\n",
        "- faster -> lr(higher)\n",
        "- weight init inpact reduce\n",
        "- a side positive impact of regularizer"
      ],
      "metadata": {
        "id": "lrUM9Vmy6_jR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nUq6XSnpHBc"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(3, activation='relu', input_dim=2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    }
  ]
}